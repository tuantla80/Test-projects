{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Score = 18.5\n",
    "Key points: \n",
    "    (1) 'tf_efficientnet_b0_ns' pretrain model from timm library\n",
    "    (2) Data Augmentation for images in the image dataset\n",
    "    (3) Use both image (128 neurons) and 12 useful_features = ['Subject Focus', 'Eyes', 'Face',\n",
    "        'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
    "        \n",
    "        nn.Linear(model.classifier.in_features, 128) \n",
    "        nn.Dropout(0.1)\n",
    "        out = nn.Linear(128 + 12, 1)    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At \"Add data\": add tez-lib and timmaster to input folder so don't need \"internet\" on.\n",
    "```\n",
    "If having \"internet\" on\n",
    "!pip install tez\n",
    "!pip install timm   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-02T10:31:10.196032Z",
     "iopub.status.busy": "2021-10-02T10:31:10.195424Z",
     "iopub.status.idle": "2021-10-02T10:31:10.280005Z",
     "shell.execute_reply": "2021-10-02T10:31:10.278684Z",
     "shell.execute_reply.started": "2021-10-02T10:31:10.195934Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "sys.path.append(\"../input/timmmaster/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-02T10:31:16.02894Z",
     "iopub.status.busy": "2021-10-02T10:31:16.027957Z",
     "iopub.status.idle": "2021-10-02T10:31:18.552114Z",
     "shell.execute_reply": "2021-10-02T10:31:18.551012Z",
     "shell.execute_reply.started": "2021-10-02T10:31:16.028885Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tez            # a simple pytorch trainer\n",
    "from tez.callbacks import EarlyStopping\n",
    "import albumentations # Fast image augmentation library\n",
    "import pandas as pd\n",
    "import cv2            # OpenCV \n",
    "import numpy as np\n",
    "import timm           # (Unofficial) PyTorch Image Models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics, model_selection\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# %matplotlib inline\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-02T10:31:18.554994Z",
     "iopub.status.busy": "2021-10-02T10:31:18.554649Z",
     "iopub.status.idle": "2021-10-02T10:31:18.562408Z",
     "shell.execute_reply": "2021-10-02T10:31:18.560715Z",
     "shell.execute_reply.started": "2021-10-02T10:31:18.554954Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "(batch_size, image_size): (64, 256), (16, 384)\n",
    "'''\n",
    "class Args:\n",
    "    batch_size = 64\n",
    "    image_size = 256\n",
    "    epochs = 10 \n",
    "    \n",
    "path_input = r'../input/petfinder-pawpularity-score/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-02T10:31:21.533514Z",
     "iopub.status.busy": "2021-10-02T10:31:21.533147Z",
     "iopub.status.idle": "2021-10-02T10:31:21.543082Z",
     "shell.execute_reply": "2021-10-02T10:31:21.542096Z",
     "shell.execute_reply.started": "2021-10-02T10:31:21.533483Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(Args.image_size,\n",
    "                              Args.image_size,\n",
    "                              p=1),\n",
    "        albumentations.HueSaturationValue(\n",
    "            hue_shift_limit=0.2,\n",
    "            sat_shift_limit=0.2,\n",
    "            val_shift_limit=0.2,\n",
    "            p=0.5\n",
    "        ),\n",
    "        albumentations.RandomBrightnessContrast(\n",
    "            brightness_limit=(-0.1, 0.1),\n",
    "            contrast_limit=(-0.1, 0.1),\n",
    "            p=0.5\n",
    "        ),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "\n",
    "valid_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(Args.image_size,\n",
    "                              Args.image_size,\n",
    "                              p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-02T10:31:23.552564Z",
     "iopub.status.busy": "2021-10-02T10:31:23.551854Z",
     "iopub.status.idle": "2021-10-02T10:31:23.559307Z",
     "shell.execute_reply": "2021-10-02T10:31:23.5579Z",
     "shell.execute_reply.started": "2021-10-02T10:31:23.552502Z"
    }
   },
   "outputs": [],
   "source": [
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(Args.image_size, Args.image_size, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-02T10:31:25.681194Z",
     "iopub.status.busy": "2021-10-02T10:31:25.680856Z",
     "iopub.status.idle": "2021-10-02T10:31:25.693249Z",
     "shell.execute_reply": "2021-10-02T10:31:25.692095Z",
     "shell.execute_reply.started": "2021-10-02T10:31:25.681137Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''To get data of each image'''\n",
    "    def __init__(self, \n",
    "                 image_paths, \n",
    "                 dense_features, \n",
    "                 targets, \n",
    "                 augmentations=None):\n",
    "        '''\n",
    "        :param dense_features: chosen feature columns\n",
    "            dense_features = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "                              'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
    "        '''\n",
    "        self.image_paths = image_paths\n",
    "        self.dense_features = dense_features\n",
    "        self.targets = targets\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        '''\n",
    "        :param item: a row index of one image data\n",
    "        return: dic\n",
    "            Eg. dic = {'image': tensor data of the image,\n",
    "                       'features': a dense features corresponding to this image, \n",
    "                       'targets': Pawpularity of this image}        \n",
    "        '''        \n",
    "        image = cv2.imread(self.image_paths[item]) # Eg. image.shape = (960, 720, 3): W, H and C\n",
    "        \n",
    "        # as opencv loads in BGR format by default, we want to show it in RGB.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Converts an image from one color space to another\n",
    "                                                       # image.shape = (960, 720, 3): C here order RGB\n",
    "            \n",
    "        if self.augmentations is not None: # refer to train_aug and valid_aug\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32) # (0, 1, 2) -> (2, 0, 1)\n",
    "                                                                  #  H, W, C   -> C, H, W  \n",
    "        features = self.dense_features[item, :]  # item is row index. Ex. item=0 is the first image       \n",
    "        targets = self.targets[item]  # value of Pawpularity of an image\n",
    "        \n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float),  # np array to torch tensor\n",
    "            'features': torch.tensor(features, dtype=torch.float), \n",
    "            'targets': torch.tensor(targets,  dtype=torch.float)            \n",
    "        }        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-02T10:31:27.64198Z",
     "iopub.status.busy": "2021-10-02T10:31:27.641394Z",
     "iopub.status.idle": "2021-10-02T10:31:27.656964Z",
     "shell.execute_reply": "2021-10-02T10:31:27.655827Z",
     "shell.execute_reply.started": "2021-10-02T10:31:27.641932Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(tez.Model):\n",
    "    '''\n",
    "    Note: in tez: Dataset === pytorch requires\n",
    "                  model class: nn.Module (pytorch) -> tez.Model\n",
    "    '''\n",
    "    def __init__(self, model_name):\n",
    "        '''\n",
    "        :param model_name: name of model for timm.create_model()\n",
    "            Eg1. model_name = 'tf_efficientnet_b0_ns'\n",
    "            Eg2. model_name = 'swin_large_patch4_window12_384'\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # model: EfficientNet\n",
    "        self.model = timm.create_model(model_name, \n",
    "                                       pretrained = True, \n",
    "                                       in_chans = 3)\n",
    "        \n",
    "        # Linear(in_features=1280, out_features=128, bias=True). print model to see the keywords\n",
    "        # Inside this model: (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
    "        # change it to:      (classifier): Linear(in_features=1280, out_features=128, bias=True)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128) \n",
    "        \n",
    "        # Dropout(p=0.1, inplace=False)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Linear(in_features=140, out_features=1, bias=True)\n",
    "        self.out = nn.Linear(128 + 12, 1)  # 12 is from dense features -> 128+12=140\n",
    "        \n",
    "        self.step_scheduler_after = 'epoch'\n",
    "        \n",
    "        # Other ways\n",
    "        # self.dropout = nn.Dropout(0.1)\n",
    "        # self.dense1 = nn.Linear(140, 64)\n",
    "        # self.dense2 = nn.Linear(64, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, image, features, targets=None):\n",
    "        x = self.model(image)  # x.shape = torch.Size([1, 128]). Eg. [[-0.0453,....0.1661]]\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        # Other ways\n",
    "        # x = self.model(image)\n",
    "        # x = self.dropout(x)\n",
    "        # x = torch.cat([x, features], dim=1)\n",
    "        # x = self.dense1(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.dense2(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = nn.MSELoss()(x, targets.view(-1, 1))\n",
    "            metrics = self.monitor_metrics(x, targets)\n",
    "            return x, loss, metrics\n",
    "        return x, 0, {}  \n",
    "        \n",
    "        \n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        \n",
    "        rmse = metrics.mean_squared_error(y_true=targets, \n",
    "                                          y_pred=outputs, \n",
    "                                          squared=False # True returns MSE, False returns RMSE\n",
    "                                         )\n",
    "        return {'rmse': rmse}\n",
    "    \n",
    "    \n",
    "    def fetch_scheduler(self):\n",
    "        '''\n",
    "        For Learning rate\n",
    "        Set the learning rate of each parameter group using a cosine annealing schedule\n",
    "        '''\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer,\n",
    "            T_0 = 10,\n",
    "            T_mult = 1,\n",
    "            eta_min = 1e-6,\n",
    "            last_epoch = -1\n",
    "        )\n",
    "        return sch\n",
    "    \n",
    "    \n",
    "    def fetch_optimizer(self):\n",
    "        ''' Adam optimization algo'''\n",
    "        opt = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr = 1e-4\n",
    "        )\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train and evaluation of dataset and Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-02T10:31:29.925985Z",
     "iopub.status.busy": "2021-10-02T10:31:29.925664Z",
     "iopub.status.idle": "2021-10-02T11:27:51.992412Z",
     "shell.execute_reply": "2021-10-02T11:27:51.989096Z",
     "shell.execute_reply.started": "2021-10-02T10:31:29.925958Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(KFold=10):\n",
    "    dense_features = [\n",
    "        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "    ]\n",
    "    \n",
    "    # Get df and create kfold column to split train and validation dataset\n",
    "    df = pd.read_csv(os.path.join(path_input, 'train.csv')).reset_index(drop = True)    \n",
    "    df[\"kfold\"] = [random.randint(0, KFold-1) for i in range(len(df))]\n",
    "    \n",
    "    for fold in range(KFold):\n",
    "        df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "        df_valid = df[df.kfold == fold].reset_index(drop=True)                           \n",
    "        print(df_train.shape, df_valid.shape)\n",
    "        \n",
    "        train_dataset = Dataset(\n",
    "            image_paths=[os.path.join(path_input, f'train/{img}.jpg') for img in df_train[\"Id\"].values],\n",
    "            dense_features=df_train[dense_features].values,\n",
    "            targets=df_train.Pawpularity.values,\n",
    "            augmentations=train_aug,\n",
    "        )\n",
    "\n",
    "        valid_dataset = Dataset(\n",
    "            image_paths=[os.path.join(path_input, f'train/{img}.jpg') for img in df_valid[\"Id\"].values] ,\n",
    "            dense_features=df_valid[dense_features].values,\n",
    "            targets=df_valid.Pawpularity.values,\n",
    "            augmentations=valid_aug,\n",
    "        )\n",
    "\n",
    "        model = Model(model_name= 'tf_efficientnet_b0_ns') \n",
    "\n",
    "        es = EarlyStopping(\n",
    "            monitor = 'valid_rmse',\n",
    "            model_path = f'model_cv{fold}.bin',\n",
    "            patience = 3,\n",
    "            mode = 'min',\n",
    "            save_weights_only = True\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            valid_dataset = valid_dataset,\n",
    "            train_bs = Args.batch_size,\n",
    "            valid_bs = 2*Args.batch_size,\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            epochs = Args.epochs,\n",
    "            callbacks = [es],\n",
    "            fp16 = True\n",
    "        )\n",
    "\n",
    "# RUN MODEL\n",
    "run(KFold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "def prediction(KFold=10):\n",
    "    dense_features = [\n",
    "            'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "            'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "        ]\n",
    "    \n",
    "    super_final_predictions = []\n",
    "    for fold in range(KFold):   \n",
    "        print(f'fold = {fold}')\n",
    "        model = Model(model_name= 'tf_efficientnet_b0_ns')         \n",
    "        model.load(f\"../input/test-model-cv01/model_cv{fold}.bin\", device=\"cuda\", weights_only=True) \n",
    "        # model.load(f\"/kaggle/working/model_cv{fold}.bin\", device=\"cuda\", weights_only=True) \n",
    "\n",
    "        df_test = pd.read_csv(os.path.join(path_input, 'test.csv'))\n",
    "        test_img_paths = [os.path.join(path_input, f'test/{img}.jpg') for img in df_test[\"Id\"].values] \n",
    "        \n",
    "        test_dataset = Dataset(\n",
    "            image_paths=test_img_paths,\n",
    "            dense_features=df_test[dense_features].values,\n",
    "            targets=np.ones(len(test_img_paths)),\n",
    "            augmentations=test_aug\n",
    "        )\n",
    "        \n",
    "        test_predictions = model.predict(test_dataset, \n",
    "                                         batch_size=2*Args.batch_size, \n",
    "                                         n_jobs=-1)\n",
    "\n",
    "        final_test_predictions = []\n",
    "        for preds in tqdm(test_predictions):\n",
    "            final_test_predictions.extend(preds.ravel().tolist())\n",
    "        # End of for preds\n",
    "        super_final_predictions.append(final_test_predictions)\n",
    "    # End of for fold\n",
    "    super_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\n",
    "    df_test[\"Pawpularity\"] = super_final_predictions\n",
    "    df_test = df_test[[\"Id\", \"Pawpularity\"]]\n",
    "    df_test.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# RUN PREDICTION\n",
    "prediction(KFold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4128bae22183829d2b5fea10effdb0c3\t    0.571777\n",
    "1\t43a2262d7738e3d420d453815151079e\t3.466797\n",
    "2\t4e429cead1848a298432a0acad014c9d\t0.738281\n",
    "3\t80bc3ccafcc51b66303c2c263aa38486\t4.218750\n",
    "4\t8f49844c382931444e68dffbe20228f4\t3.060547\n",
    "5\tb03f7041962238a7c9d6537e22f9b017\t3.275391\n",
    "6\tc978013571258ed6d4637f6e8cc9d6a3\t1.929688\n",
    "7\te0de453c1bffc20c22b072b34b54e50f\t1.901367\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
